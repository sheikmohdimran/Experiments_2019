{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Architechture_Debug.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheikmohdimran/Experiments_2019/blob/master/Vision/Pytorch_Architechture_Debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h7hEVXufoL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchsnooper -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5IGMbleJ_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torchsnooper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N-Pqsvruw4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class double_conv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2=None):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "                        diffY // 2, diffY - diffY//2))\n",
        "        \n",
        "        # for padding issues, see \n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        \n",
        "        if x2 is not None:\n",
        "            x = torch.cat([x2, x1], dim=1)\n",
        "        else:\n",
        "            x = x1\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "def get_mesh(batch_size, shape_x, shape_y):\n",
        "    mg_x, mg_y = np.meshgrid(np.linspace(0, 1, shape_y), np.linspace(0, 1, shape_x))\n",
        "    mg_x = np.tile(mg_x[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
        "    mg_y = np.tile(mg_y[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
        "    mesh = torch.cat([torch.tensor(mg_x).to(device), torch.tensor(mg_y).to(device)], 1)\n",
        "    return mesh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S9s60j0uTp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.GroupNorm(16, planes)\n",
        "\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.GroupNorm(16, planes)\n",
        "\n",
        "        if stride != 1 or inplanes != planes:\n",
        "            self.downsample = nn.Sequential(\n",
        "                conv1x1(inplanes, planes, stride), nn.GroupNorm(16, planes))\n",
        "        else:\n",
        "            self.downsample = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = F.relu(out, inplace=True)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes)\n",
        "        self.bn1 = nn.GroupNorm(16, planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.GroupNorm(16, planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.GroupNorm(16, planes * self.expansion)\n",
        "\n",
        "        if stride != 1 or inplanes != planes * self.expansion:\n",
        "            self.downsample = nn.Sequential(\n",
        "                conv1x1(inplanes, planes * self.expansion, stride), \n",
        "                nn.GroupNorm(16, planes * self.expansion))\n",
        "        else:\n",
        "            self.downsample = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
        "        out = self.bn3(self.conv3(out))\n",
        " \n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetFeatures(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
        "        super(ResNetFeatures, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.GroupNorm(16, 64)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        conv1 = F.max_pool2d(conv1, 3, stride=2, padding=1)\n",
        "\n",
        "        x = self.layer1(conv1)\n",
        "        feats8 = self.layer2(x)\n",
        "        feats16 = self.layer3(feats8)\n",
        "        feats32 = self.layer4(feats16)\n",
        "\n",
        "        return feats8,feats16,feats32\n",
        "\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetFeatures(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        _load_pretrained(model, model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\t\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetFeatures(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        _load_pretrained(model, model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "def _load_pretrained(model, pretrained):\n",
        "    model_dict = model.state_dict()\n",
        "    pretrained = {k : v for k, v in pretrained.items() if k in model_dict}\n",
        "    model_dict.update(pretrained)\n",
        "    model.load_state_dict(model_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn28EMipfhHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=resnet18(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vsux-l9eXoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torchsnooper.snoop()\n",
        "class CentResnet(nn.Module):\n",
        "    '''Mixture of previous classes'''\n",
        "    def __init__(self, n_classes):\n",
        "        super(CentResnet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        \n",
        "        # Lateral layers convert resnet outputs to a common feature size\n",
        "        self.lat8 = nn.Conv2d(128, 256, 1)\n",
        "        self.lat16 = nn.Conv2d(256, 256, 1)\n",
        "        self.lat32 = nn.Conv2d(512, 256, 1)\n",
        "        self.bn8 = nn.GroupNorm(16, 256)\n",
        "        self.bn16 = nn.GroupNorm(16, 256)\n",
        "        self.bn32 = nn.GroupNorm(16, 256)\n",
        "\n",
        "        self.conv0 = double_conv(5, 64)\n",
        "        self.conv1 = double_conv(64, 128)\n",
        "        self.conv2 = double_conv(128, 512)\n",
        "        self.conv3 = double_conv(512, 1024)\n",
        "        \n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.up1 = up(1282 , 512) #+ 1024\n",
        "        self.up2 = up(512 + 512, 256)\n",
        "        self.outc = nn.Conv2d(256, n_classes, 1)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
        "        x0 = torch.cat([x, mesh1], 1)\n",
        "        x1 = self.mp(self.conv0(x0))\n",
        "        x2 = self.mp(self.conv1(x1))\n",
        "        x3 = self.mp(self.conv2(x2))\n",
        "        x4 = self.mp(self.conv3(x3))\n",
        "        \n",
        "        # Run frontend network\n",
        "        feats8, feats16,feats32 = self.base_model(x)\n",
        "        lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
        "        lat16 = F.relu(self.bn16(self.lat16(feats16)))\n",
        "        lat32 = F.relu(self.bn32(self.lat32(feats32)))\n",
        "        \n",
        "        # Add positional info\n",
        "        mesh2 = get_mesh(batch_size, lat32.shape[2], lat32.shape[3])\n",
        "        feats = torch.cat([lat32, mesh2], 1)\n",
        "        x = self.up1(feats, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.outc(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTzvvxLsedoQ",
        "colab_type": "code",
        "outputId": "4bb3f9a7-aa63-4359-aa25-2adffbf24dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CentResnet(8).to(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source path:... <ipython-input-7-6c73de720edf>\n",
            "Starting var:.. self = REPR FAILED\n",
            "Starting var:.. n_classes = 8\n",
            "Starting var:.. __class__ = <class '__main__.CentResnet'>\n",
            "06:21:56.948217 call         4     def __init__(self, n_classes):\n",
            "06:21:56.952803 line         5         super(CentResnet, self).__init__()\n",
            "Modified var:.. self = CentResnet()\n",
            "06:21:56.953210 line         6         self.base_model = base_model\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...(16, 512, eps=1e-05, affine=True)      )    )  ))\n",
            "06:21:56.953739 line         9         self.lat8 = nn.Conv2d(128, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(128, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:21:56.957147 line        10         self.lat16 = nn.Conv2d(256, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(256, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:21:56.959033 line        11         self.lat32 = nn.Conv2d(512, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(512, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:21:56.961642 line        12         self.bn8 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...bn8): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:21:56.962808 line        13         self.bn16 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...n16): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:21:56.963847 line        14         self.bn32 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...n32): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:21:56.964869 line        16         self.conv0 = double_conv(5, 64)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...stats=True)      (5): ReLU(inplace=True)    )  ))\n",
            "06:21:56.971596 line        17         self.conv1 = double_conv(64, 128)\n",
            "06:21:56.975681 line        18         self.conv2 = double_conv(128, 512)\n",
            "06:21:57.001572 line        19         self.conv3 = double_conv(512, 1024)\n",
            "06:21:57.119034 line        21         self.mp = nn.MaxPool2d(2)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...tride=2, padding=0, dilation=1, ceil_mode=False))\n",
            "06:21:57.120355 line        23         self.up1 = up(1282 , 512) #+ 1024\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...e)        (5): ReLU(inplace=True)      )    )  ))\n",
            "06:21:57.196278 line        24         self.up2 = up(512 + 512, 256)\n",
            "06:21:57.222810 line        25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:21:57.224160 return      25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Return value:.. None\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE8crmQtejeG",
        "colab_type": "code",
        "outputId": "2d81cd03-5f10-4f44-c972-e0b5fe7f8291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "img_batch = torch.randn((1,3,512,2048))\n",
        "test = model(img_batch.to(device))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "Starting var:.. x = tensor<(1, 3, 512, 2048), float32, cuda:0>\n",
            "06:22:02.373339 call        28     def forward(self, x):\n",
            "06:22:02.409489 line        29         batch_size = x.shape[0]\n",
            "New var:....... batch_size = 1\n",
            "06:22:02.412173 line        30         mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
            "New var:....... mesh1 = tensor<(1, 2, 512, 2048), float32, cuda:0>\n",
            "06:22:02.522144 line        31         x0 = torch.cat([x, mesh1], 1)\n",
            "New var:....... x0 = tensor<(1, 5, 512, 2048), float32, cuda:0>\n",
            "06:22:02.526005 line        32         x1 = self.mp(self.conv0(x0))\n",
            "New var:....... x1 = tensor<(1, 64, 256, 1024), float32, cuda:0, grad>\n",
            "06:22:02.542043 line        33         x2 = self.mp(self.conv1(x1))\n",
            "New var:....... x2 = tensor<(1, 128, 128, 512), float32, cuda:0, grad>\n",
            "06:22:02.767264 line        34         x3 = self.mp(self.conv2(x2))\n",
            "New var:....... x3 = tensor<(1, 512, 64, 256), float32, cuda:0, grad>\n",
            "06:22:02.905226 line        35         x4 = self.mp(self.conv3(x3))\n",
            "New var:....... x4 = tensor<(1, 1024, 32, 128), float32, cuda:0, grad>\n",
            "06:22:03.177830 line        38         feats8, feats16,feats32 = self.base_model(x)\n",
            "New var:....... feats8 = tensor<(1, 128, 64, 256), float32, cuda:0, grad>\n",
            "New var:....... feats16 = tensor<(1, 256, 32, 128), float32, cuda:0, grad>\n",
            "New var:....... feats32 = tensor<(1, 512, 16, 64), float32, cuda:0, grad>\n",
            "06:22:03.486552 line        39         lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
            "New var:....... lat8 = tensor<(1, 256, 64, 256), float32, cuda:0, grad>\n",
            "06:22:03.590728 line        40         lat16 = F.relu(self.bn16(self.lat16(feats16)))\n",
            "New var:....... lat16 = tensor<(1, 256, 32, 128), float32, cuda:0, grad>\n",
            "06:22:03.609590 line        41         lat32 = F.relu(self.bn32(self.lat32(feats32)))\n",
            "New var:....... lat32 = tensor<(1, 256, 16, 64), float32, cuda:0, grad>\n",
            "06:22:03.626674 line        44         mesh2 = get_mesh(batch_size, lat32.shape[2], lat32.shape[3])\n",
            "New var:....... mesh2 = tensor<(1, 2, 16, 64), float32, cuda:0>\n",
            "06:22:03.643637 line        45         feats = torch.cat([lat32, mesh2], 1)\n",
            "New var:....... feats = tensor<(1, 258, 16, 64), float32, cuda:0, grad>\n",
            "06:22:03.660252 line        46         x = self.up1(feats, x4)\n",
            "Modified var:.. x = tensor<(1, 512, 32, 128), float32, cuda:0, grad>\n",
            "06:22:03.684616 line        47         x = self.up2(x, x3)\n",
            "Modified var:.. x = tensor<(1, 256, 64, 256), float32, cuda:0, grad>\n",
            "06:22:03.759130 line        48         x = self.outc(x)\n",
            "Modified var:.. x = tensor<(1, 8, 64, 256), float32, cuda:0, grad>\n",
            "06:22:03.829689 line        49         return x\n",
            "06:22:03.844784 return      49         return x\n",
            "Return value:.. tensor<(1, 8, 64, 256), float32, cuda:0, grad>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzL28uHRey3T",
        "colab_type": "code",
        "outputId": "baa98635-9baf-4e07-dcad-8b578f5af381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "del model\n",
        "base_model=resnet50(pretrained=False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CentResnet(8).to(device)\n",
        "img_batch = torch.randn((1,3,512,2048))\n",
        "test = model(img_batch.to(device))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting var:.. self = REPR FAILED\n",
            "Starting var:.. n_classes = 8\n",
            "Starting var:.. __class__ = <class '__main__.CentResnet'>\n",
            "06:22:04.265948 call         4     def __init__(self, n_classes):\n",
            "06:22:04.266648 line         5         super(CentResnet, self).__init__()\n",
            "Modified var:.. self = CentResnet()\n",
            "06:22:04.266928 line         6         self.base_model = base_model\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...16, 2048, eps=1e-05, affine=True)      )    )  ))\n",
            "06:22:04.267190 line         9         self.lat8 = nn.Conv2d(128, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(128, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:04.269310 line        10         self.lat16 = nn.Conv2d(256, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(256, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:04.271357 line        11         self.lat32 = nn.Conv2d(512, 256, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...v2d(512, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:04.273837 line        12         self.bn8 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...bn8): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:04.275327 line        13         self.bn16 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...n16): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:04.276676 line        14         self.bn32 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...n32): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:04.278082 line        16         self.conv0 = double_conv(5, 64)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...stats=True)      (5): ReLU(inplace=True)    )  ))\n",
            "06:22:04.280876 line        17         self.conv1 = double_conv(64, 128)\n",
            "06:22:04.285089 line        18         self.conv2 = double_conv(128, 512)\n",
            "06:22:04.309889 line        19         self.conv3 = double_conv(512, 1024)\n",
            "06:22:04.427404 line        21         self.mp = nn.MaxPool2d(2)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...tride=2, padding=0, dilation=1, ceil_mode=False))\n",
            "06:22:04.429366 line        23         self.up1 = up(1282 , 512) #+ 1024\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...e)        (5): ReLU(inplace=True)      )    )  ))\n",
            "06:22:04.504277 line        24         self.up2 = up(512 + 512, 256)\n",
            "06:22:04.533045 line        25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Modified var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:04.535206 return      25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Return value:.. None\n",
            "Starting var:.. self = CentResnet(  (base_model): ResNetFeatures(    (c...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "Starting var:.. x = tensor<(1, 3, 512, 2048), float32, cuda:0>\n",
            "06:22:04.616998 call        28     def forward(self, x):\n",
            "06:22:04.620035 line        29         batch_size = x.shape[0]\n",
            "New var:....... batch_size = 1\n",
            "06:22:04.622362 line        30         mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
            "New var:....... mesh1 = tensor<(1, 2, 512, 2048), float32, cuda:0>\n",
            "06:22:04.639835 line        31         x0 = torch.cat([x, mesh1], 1)\n",
            "New var:....... x0 = tensor<(1, 5, 512, 2048), float32, cuda:0>\n",
            "06:22:04.644407 line        32         x1 = self.mp(self.conv0(x0))\n",
            "New var:....... x1 = tensor<(1, 64, 256, 1024), float32, cuda:0, grad>\n",
            "06:22:04.653856 line        33         x2 = self.mp(self.conv1(x1))\n",
            "New var:....... x2 = tensor<(1, 128, 128, 512), float32, cuda:0, grad>\n",
            "06:22:04.813235 line        34         x3 = self.mp(self.conv2(x2))\n",
            "New var:....... x3 = tensor<(1, 512, 64, 256), float32, cuda:0, grad>\n",
            "06:22:04.929488 line        35         x4 = self.mp(self.conv3(x3))\n",
            "New var:....... x4 = tensor<(1, 1024, 32, 128), float32, cuda:0, grad>\n",
            "06:22:05.173945 line        38         feats8, feats16,feats32 = self.base_model(x)\n",
            "New var:....... feats8 = tensor<(1, 512, 64, 256), float32, cuda:0, grad>\n",
            "New var:....... feats16 = tensor<(1, 1024, 32, 128), float32, cuda:0, grad>\n",
            "New var:....... feats32 = tensor<(1, 2048, 16, 64), float32, cuda:0, grad>\n",
            "06:22:05.538659 line        39         lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
            "06:22:05.800858 exception   39         lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
            "RuntimeError: Given groups=1, weight of size 256...o have 128 channels, but got 512 channels instead\n",
            "Call ended by exception\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-688f4d9f8dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCentResnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pysnooper/tracer.py\u001b[0m in \u001b[0;36msimple_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msimple_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6c73de720edf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Run frontend network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mfeats8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlat8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlat8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlat16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlat32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 256 128 1 1, expected input[1, 512, 64, 256] to have 128 channels, but got 512 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXTbONi6fsrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torchsnooper.snoop()\n",
        "class CentResnet1(nn.Module):\n",
        "    '''Mixture of previous classes'''\n",
        "    def __init__(self, n_classes):\n",
        "        super(CentResnet1, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        \n",
        "        # Lateral layers convert resnet outputs to a common feature size\n",
        "        self.lat8 = nn.Conv2d(512, 256, 1)\n",
        "        self.lat16 = nn.Conv2d(1024, 256, 1)\n",
        "        self.lat32 = nn.Conv2d(2048, 256, 1)\n",
        "        self.bn8 = nn.GroupNorm(16, 256)\n",
        "        self.bn16 = nn.GroupNorm(16, 256)\n",
        "        self.bn32 = nn.GroupNorm(16, 256)\n",
        "\n",
        "        self.conv0 = double_conv(5, 64)\n",
        "        self.conv1 = double_conv(64, 128)\n",
        "        self.conv2 = double_conv(128, 512)\n",
        "        self.conv3 = double_conv(512, 1024)\n",
        "        \n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.up1 = up(1282 , 512) #+ 1024\n",
        "        self.up2 = up(512 + 512, 256)\n",
        "        self.outc = nn.Conv2d(256, n_classes, 1)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
        "        x0 = torch.cat([x, mesh1], 1)\n",
        "        x1 = self.mp(self.conv0(x0))\n",
        "        x2 = self.mp(self.conv1(x1))\n",
        "        x3 = self.mp(self.conv2(x2))\n",
        "        x4 = self.mp(self.conv3(x3))\n",
        "        \n",
        "        # Run frontend network\n",
        "        feats8, feats16, feats32 = self.base_model(x)\n",
        "        lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
        "        lat16 = F.relu(self.bn16(self.lat16(feats16)))\n",
        "        lat32 = F.relu(self.bn32(self.lat32(feats32)))\n",
        "        \n",
        "        # Add positional info\n",
        "        mesh2 = get_mesh(batch_size, lat32.shape[2], lat32.shape[3])\n",
        "        feats = torch.cat([lat32, mesh2], 1)\n",
        "        x = self.up1(feats, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.outc(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW-5Lx0GhKTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22d6a1f3-0415-4787-bf34-db804a7edc5e"
      },
      "source": [
        "base_model=resnet50(pretrained=False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CentResnet1(8).to(device)\n",
        "img_batch = torch.randn((1,3,512,2048))\n",
        "test = model(img_batch.to(device))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source path:... <ipython-input-4-9ac2feb4a147>\n",
            "Starting var:.. self = REPR FAILED\n",
            "Starting var:.. n_classes = 8\n",
            "Starting var:.. __class__ = <class '__main__.CentResnet1'>\n",
            "06:22:58.848489 call         4     def __init__(self, n_classes):\n",
            "06:22:58.849016 line         5         super(CentResnet1, self).__init__()\n",
            "Modified var:.. self = CentResnet1()\n",
            "06:22:58.849206 line         6         self.base_model = base_model\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...16, 2048, eps=1e-05, affine=True)      )    )  ))\n",
            "06:22:58.849362 line         9         self.lat8 = nn.Conv2d(512, 256, 1)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...v2d(512, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:58.852840 line        10         self.lat16 = nn.Conv2d(1024, 256, 1)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...2d(1024, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:58.856627 line        11         self.lat32 = nn.Conv2d(2048, 256, 1)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...2d(2048, 256, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:58.862560 line        12         self.bn8 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...bn8): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:58.864155 line        13         self.bn16 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...n16): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:58.865790 line        14         self.bn32 = nn.GroupNorm(16, 256)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...n32): GroupNorm(16, 256, eps=1e-05, affine=True))\n",
            "06:22:58.867400 line        16         self.conv0 = double_conv(5, 64)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...stats=True)      (5): ReLU(inplace=True)    )  ))\n",
            "06:22:58.870642 line        17         self.conv1 = double_conv(64, 128)\n",
            "06:22:58.875097 line        18         self.conv2 = double_conv(128, 512)\n",
            "06:22:58.901100 line        19         self.conv3 = double_conv(512, 1024)\n",
            "06:22:59.017496 line        21         self.mp = nn.MaxPool2d(2)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...tride=2, padding=0, dilation=1, ceil_mode=False))\n",
            "06:22:59.019127 line        23         self.up1 = up(1282 , 512) #+ 1024\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...e)        (5): ReLU(inplace=True)      )    )  ))\n",
            "06:22:59.089926 line        24         self.up2 = up(512 + 512, 256)\n",
            "06:22:59.116342 line        25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Modified var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "06:22:59.118328 return      25         self.outc = nn.Conv2d(256, n_classes, 1)\n",
            "Return value:.. None\n",
            "Starting var:.. self = CentResnet1(  (base_model): ResNetFeatures(    (...onv2d(256, 8, kernel_size=(1, 1), stride=(1, 1)))\n",
            "Starting var:.. x = tensor<(1, 3, 512, 2048), float32, cuda:0>\n",
            "06:23:01.482112 call        28     def forward(self, x):\n",
            "06:23:01.486164 line        29         batch_size = x.shape[0]\n",
            "New var:....... batch_size = 1\n",
            "06:23:01.489039 line        30         mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
            "New var:....... mesh1 = tensor<(1, 2, 512, 2048), float32, cuda:0>\n",
            "06:23:01.509383 line        31         x0 = torch.cat([x, mesh1], 1)\n",
            "New var:....... x0 = tensor<(1, 5, 512, 2048), float32, cuda:0>\n",
            "06:23:01.514063 line        32         x1 = self.mp(self.conv0(x0))\n",
            "New var:....... x1 = tensor<(1, 64, 256, 1024), float32, cuda:0, grad>\n",
            "06:23:01.524395 line        33         x2 = self.mp(self.conv1(x1))\n",
            "New var:....... x2 = tensor<(1, 128, 128, 512), float32, cuda:0, grad>\n",
            "06:23:01.747551 line        34         x3 = self.mp(self.conv2(x2))\n",
            "New var:....... x3 = tensor<(1, 512, 64, 256), float32, cuda:0, grad>\n",
            "06:23:01.885591 line        35         x4 = self.mp(self.conv3(x3))\n",
            "New var:....... x4 = tensor<(1, 1024, 32, 128), float32, cuda:0, grad>\n",
            "06:23:02.166068 line        38         feats8, feats16, feats32 = self.base_model(x)\n",
            "New var:....... feats8 = tensor<(1, 512, 64, 256), float32, cuda:0, grad>\n",
            "New var:....... feats16 = tensor<(1, 1024, 32, 128), float32, cuda:0, grad>\n",
            "New var:....... feats32 = tensor<(1, 2048, 16, 64), float32, cuda:0, grad>\n",
            "06:23:02.496205 line        39         lat8 = F.relu(self.bn8(self.lat8(feats8)))\n",
            "New var:....... lat8 = tensor<(1, 256, 64, 256), float32, cuda:0, grad>\n",
            "06:23:02.717771 line        40         lat16 = F.relu(self.bn16(self.lat16(feats16)))\n",
            "New var:....... lat16 = tensor<(1, 256, 32, 128), float32, cuda:0, grad>\n",
            "06:23:02.739267 line        41         lat32 = F.relu(self.bn32(self.lat32(feats32)))\n",
            "New var:....... lat32 = tensor<(1, 256, 16, 64), float32, cuda:0, grad>\n",
            "06:23:02.759532 line        44         mesh2 = get_mesh(batch_size, lat32.shape[2], lat32.shape[3])\n",
            "New var:....... mesh2 = tensor<(1, 2, 16, 64), float32, cuda:0>\n",
            "06:23:02.780201 line        45         feats = torch.cat([lat32, mesh2], 1)\n",
            "New var:....... feats = tensor<(1, 258, 16, 64), float32, cuda:0, grad>\n",
            "06:23:02.798212 line        46         x = self.up1(feats, x4)\n",
            "Modified var:.. x = tensor<(1, 512, 32, 128), float32, cuda:0, grad>\n",
            "06:23:02.819752 line        47         x = self.up2(x, x3)\n",
            "Modified var:.. x = tensor<(1, 256, 64, 256), float32, cuda:0, grad>\n",
            "06:23:02.892147 line        48         x = self.outc(x)\n",
            "Modified var:.. x = tensor<(1, 8, 64, 256), float32, cuda:0, grad>\n",
            "06:23:02.964031 line        49         return x\n",
            "06:23:02.981080 return      49         return x\n",
            "Return value:.. tensor<(1, 8, 64, 256), float32, cuda:0, grad>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOMX-nMMhNcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}